{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Experimental Results & Generate Latex Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)\n",
    "1. [Distribution of POI Visit Duration](#1.-Distribution-of-POI-Visit-Duration)\n",
    "1. [Distribution of POI Popularity & #Visits](#2.-Distribution-of-POI-Popularity-&-#Visits)\n",
    "1. [POI Categories](#3.-POI-Categories)\n",
    "1. [Latex Table for Dataset Statistics](#4.-Latex-Table-for-Dataset-Statistics)\n",
    "1. [Latex Table for Recommendation Results](#5.-Latex-Table-for-Recommendation-Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import os, pickle, types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ijcai = 'data/data-ijcai15'\n",
    "#data_recsys = 'data/data-recsys16'\n",
    "data_recsys = 'data/data-cikm16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_suffix = ['Edin', 'Glas', 'Melb', 'Osak', 'Toro']\n",
    "dat_names = ['Edinburgh', 'Glasgow', 'Melbourne', 'Osaka', 'Toronto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_types = ['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods_all = ['\\\\textsc{Random}', '\\\\textsc{PersTour}\\cite{ijcai15}', '\\\\textsc{PersTour-L}', \\\n",
    "               '\\\\textsc{PoiPopularity}', '\\\\textsc{PoiRank}', '\\\\textsc{Markov}', '\\\\textsc{MarkovPath}', \\\n",
    "               '\\\\textsc{Rank+Markov}', '\\\\textsc{Rank+MarkovPath}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_photos = [82060, 29019, 94142, 392420, 157505]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Distribution of POI Visit Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15, 2])\n",
    "for dat_ix in range(len(dat_suffix)):\n",
    "    ftraj = os.path.join(data_recsys, 'traj-noloop-all-' + dat_suffix[dat_ix] + '.csv')\n",
    "    traj_all = pd.read_csv(ftraj)\n",
    "    plt.subplot(1, len(dat_suffix), dat_ix+1)\n",
    "    ax = traj_all['poiDuration'].hist(bins=20)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    #ax.set_xlim(left=1)\n",
    "    if dat_ix == len(dat_suffix)-2:\n",
    "        ax.set_xlim(left=500)\n",
    "    if dat_ix == len(dat_suffix)-1:\n",
    "        ax.set_xlim(left=2000)\n",
    "    \n",
    "    ax.set_title(dat_names[dat_ix])\n",
    "    if dat_ix == 2:\n",
    "        ax.set_xlabel('POI Visit Duration (seconds)')\n",
    "    if dat_ix == 0:\n",
    "        ax.set_ylabel('#POI Visits')\n",
    "pdf = PdfPages('visit_duration.pdf')\n",
    "pdf.savefig(fig)\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distribution of POI Popularity & #Visits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute POI properties, e.g., popularity, total number of visit, average visit duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_poi_info(trajid_list, traj_all, poi_all):\n",
    "    assert(len(trajid_list) > 0)\n",
    "    # to allow duplicated trajid\n",
    "    poi_info = traj_all[traj_all['trajID'] == trajid_list[0]][['poiID', 'poiDuration']].copy() \n",
    "    for i in range(1, len(trajid_list)):\n",
    "        traj = traj_all[traj_all['trajID'] == trajid_list[i]][['poiID', 'poiDuration']]\n",
    "        poi_info = poi_info.append(traj, ignore_index=True)\n",
    "    \n",
    "    poi_info = poi_info.groupby('poiID').agg([np.mean, np.size])\n",
    "    poi_info.columns = poi_info.columns.droplevel()\n",
    "    poi_info.reset_index(inplace=True)\n",
    "    poi_info.rename(columns={'mean':'avgDuration', 'size':'nVisit'}, inplace=True)\n",
    "    poi_info.set_index('poiID', inplace=True) \n",
    "    poi_info['poiCat'] = poi_all.loc[poi_info.index, 'poiCat']\n",
    "    poi_info['poiLon'] = poi_all.loc[poi_info.index, 'poiLon']\n",
    "    poi_info['poiLat'] = poi_all.loc[poi_info.index, 'poiLat']\n",
    "    \n",
    "    # POI popularity: the number of distinct users that visited the POI\n",
    "    pop_df = traj_all[traj_all['trajID'].isin(trajid_list)][['poiID', 'userID']].copy()\n",
    "    pop_df = pop_df.groupby('poiID').agg(pd.Series.nunique)\n",
    "    pop_df.rename(columns={'userID':'nunique'}, inplace=True)\n",
    "    poi_info['popularity'] = pop_df.loc[poi_info.index, 'nunique']\n",
    "    \n",
    "    return poi_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15, 2])\n",
    "for dat_ix in range(len(dat_suffix)):\n",
    "    fpoi = os.path.join(data_recsys, 'poi-' + dat_suffix[dat_ix] + '.csv')\n",
    "    ftraj = os.path.join(data_recsys, 'traj-noloop-all-' + dat_suffix[dat_ix] + '.csv')\n",
    "    poi_all = pd.read_csv(fpoi)\n",
    "    poi_all.set_index('poiID', inplace=True)\n",
    "    traj_all = pd.read_csv(ftraj)\n",
    "    poi_info = calc_poi_info(traj_all['trajID'].unique(), traj_all, poi_all)\n",
    "    plt.subplot(1, len(dat_suffix), dat_ix+1)\n",
    "    #ax = poi_info['popularity'].hist(bins=8)\n",
    "    ax = poi_info['nVisit'].hist(bins=8)\n",
    "    \n",
    "    ax.set_title(dat_names[dat_ix])\n",
    "    if dat_ix == 2:\n",
    "        #ax.set_xlabel('POI Popularity')\n",
    "        ax.set_xlabel('#Visits at POI')\n",
    "    if dat_ix == 0:\n",
    "        ax.set_ylabel('#POIs')\n",
    "    labels = ax.get_xticklabels()\n",
    "    plt.setp(labels, rotation=30, fontsize=10)\n",
    "#pdf = PdfPages('poi_popularity.pdf')\n",
    "pdf = PdfPages('poi_nvisit.pdf')\n",
    "pdf.savefig(fig)\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. POI Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_set = set()\n",
    "for dat_ix in range(len(dat_suffix)):\n",
    "    fpoi = os.path.join(data_recsys, 'poi-' + dat_suffix[dat_ix] + '.csv')\n",
    "    ftraj = os.path.join(data_recsys, 'traj-noloop-all-' + dat_suffix[dat_ix] + '.csv')\n",
    "    poi_all = pd.read_csv(fpoi)\n",
    "    traj_all = pd.read_csv(ftraj)\n",
    "    poi_all.set_index('poiID', inplace=True)\n",
    "    cats = sorted(poi_all.loc[traj_all['poiID'].unique(), 'poiCat'].unique())\n",
    "    cat_set = cat_set | set(cats)\n",
    "    cat_str = ''.join([x + ', ' for x in cats])\n",
    "    print('%s: %s' % (dat_names[dat_ix], cat_str[:-2]))\n",
    "print('\\n%s' % sorted(cat_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Latex Table for Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strs = []\n",
    "for dset in dat_types:\n",
    "    if dset == 'all':     \n",
    "        title = 'of all trajectories without loops'\n",
    "        noloop = True\n",
    "    if dset == 'nofew':   \n",
    "        title = 'of users with more than 5 (including 5) trajectories with loops'\n",
    "        noloop = False\n",
    "    strs.append('\\\\begin{table*}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    #strs.append('\\\\caption{Dataset ' + title + '}\\n')\n",
    "    #strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{' + 'l' + 5*'r' + '} \\\\hline\\n')\n",
    "    #strs.append('\\\\textbf{City} & \\\\textbf{\\\\#POIs} & \\\\textbf{\\\\#Users} & ')\n",
    "    #strs.append('\\\\textbf{\\\\#POI Visits} & \\\\textbf{\\\\#Trajectories} & \\\\textbf{\\\\#TotalNodes} \\\\\\\\ \\\\hline\\n')\n",
    "    strs.append('\\\\textbf{Dataset} & \\\\textbf{\\\\#Photos} & \\\\textbf{\\\\#POI Visits} & \\\\textbf{\\\\#Trajectories} & ')\n",
    "    strs.append('\\\\textbf{\\\\#Users} \\\\\\\\ \\\\hline\\n')\n",
    "    \n",
    "    for dat_ix in range(len(dat_names)):\n",
    "        if noloop == True:\n",
    "            ftraj = os.path.join(data_recsys, 'traj-noloop-' + dset + '-' + dat_suffix[dat_ix] + '.csv')\n",
    "        else:\n",
    "            ftraj = os.path.join(data_recsys, 'traj-' + dset + '-' + dat_suffix[dat_ix] + '.csv')\n",
    "        traj_df = pd.read_csv(ftraj)\n",
    "        total_nodes = traj_df[['trajID', 'trajLen']].copy().groupby('trajID').first().sum().values[0]\n",
    "        strs.append(dat_names[dat_ix])\n",
    "        #strs.append(' & ' + '{:,}'.format(traj_df['poiID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(num_photos[dat_ix]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['#photo'].sum()))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['trajID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['userID'].unique().shape[0]))\n",
    "        #strs.append(' & ' + '{:,}'.format(total_nodes))\n",
    "        strs.append(' \\\\\\\\ \\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\caption{Statistics of trajectory dataset}\\n')\n",
    "    strs.append('\\\\label{table:data}\\n')\n",
    "    strs.append('\\\\end{table*}\\n\\n')\n",
    "print(''.join(strs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Latex Table for Recommendation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate results filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fname(dat_ix, type_ix, noloop):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    assert(0 <= type_ix < len(dat_types))\n",
    "    assert(isinstance(noloop, bool))\n",
    "    \n",
    "    if noloop == True:\n",
    "        loop_str = 'noloop-'\n",
    "    else:\n",
    "        loop_str = ''\n",
    "    \n",
    "    type_str = dat_types[type_ix] + '-agnostic-'\n",
    "    suffix = dat_suffix[dat_ix] + '.pkl'\n",
    "    \n",
    "    fname = loop_str + type_str\n",
    "    frank = os.path.join(data_recsys, 'rank-' + fname + suffix)\n",
    "    ftran = os.path.join(data_recsys, 'tran-' + fname + suffix)\n",
    "    fcomb = os.path.join(data_recsys, 'comb-' + fname + '0_5-' + suffix)\n",
    "    frand  = os.path.join(data_recsys, 'rand-' + fname + suffix)\n",
    "    fijcai = os.path.join(data_ijcai, 'ijcai-' + dat_suffix[dat_ix] + '.pkl')\n",
    "    return frank, ftran, fcomb, frand, fijcai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_fname(1, 0, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the F1 score for recommended trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_F1(traj_act, traj_rec, noloop=False):\n",
    "    '''Compute recall, precision and F1 for recommended trajectories'''\n",
    "    assert(isinstance(noloop, bool))\n",
    "    assert(len(traj_act) > 0)\n",
    "    assert(len(traj_rec) > 0)\n",
    "    \n",
    "    if noloop == True:\n",
    "        intersize = len(set(traj_act) & set(traj_rec))\n",
    "    else:\n",
    "        match_tags = np.zeros(len(traj_act), dtype=np.bool)\n",
    "        for poi in traj_rec:\n",
    "            for j in range(len(traj_act)):\n",
    "                if match_tags[j] == False and poi == traj_act[j]:\n",
    "                    match_tags[j] = True\n",
    "                    break\n",
    "        intersize = np.nonzero(match_tags)[0].shape[0]\n",
    "        \n",
    "    recall = intersize / len(traj_act)\n",
    "    precision = intersize / len(traj_rec)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_pairsF1(seq_act, seq_rec):\n",
    "    assert(len(seq_act) > 0)\n",
    "    assert(len(seq_act) == len(set(seq_act))) # no loops in seq_act\n",
    "    n = len(seq_act)\n",
    "    nr = len(seq_rec)\n",
    "    n0 = n*(n-1) / 2\n",
    "    n0r = nr*(nr-1) / 2\n",
    "    \n",
    "    # seq_act determines the correct visiting order\n",
    "    order_df = pd.DataFrame(data=np.zeros((n, n), dtype=np.bool), columns=seq_act, index=seq_act)\n",
    "    for i in range(n):\n",
    "        poi1 = seq_act[i]\n",
    "        for j in range(i+1, n):\n",
    "            poi2 = seq_act[j]\n",
    "            order_df.loc[poi1, poi2] = True\n",
    "            \n",
    "    nc = 0\n",
    "    for i in range(nr):\n",
    "        poi1 = seq_rec[i]\n",
    "        for j in range(i+1, nr):\n",
    "            poi2 = seq_rec[j]\n",
    "            if poi1 in seq_act and poi2 in seq_act:\n",
    "                if poi1 != poi2:\n",
    "                    if order_df.loc[poi1, poi2] == True: nc += 1\n",
    "    \n",
    "    precision = nc / n0r\n",
    "    recall = nc / n0\n",
    "    if nc == 0:\n",
    "        F1 = 0\n",
    "    else:\n",
    "        F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_results(dat_ix, type_ix):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    assert(0 <= type_ix < len(dat_types))\n",
    "    \n",
    "    noloop = True\n",
    "    \n",
    "    frank, ftran, fcomb, frand, fijcai = gen_fname(dat_ix, type_ix, noloop)\n",
    "    #print(frank)\n",
    "    assert(os.path.exists(frank))\n",
    "    #print(ftran)\n",
    "    assert(os.path.exists(ftran))\n",
    "    #print(fcomb)\n",
    "    assert(os.path.exists(fcomb))\n",
    "    #print(frand)\n",
    "    assert(os.path.exists(frand))\n",
    "    #print(fijcai)\n",
    "    assert(os.path.exists(fijcai))\n",
    "\n",
    "    # load results data\n",
    "    recdict_rank = pickle.load(open(frank, 'rb'))\n",
    "    recdict_tran = pickle.load(open(ftran, 'rb'))\n",
    "    recdict_comb = pickle.load(open(fcomb, 'rb'))\n",
    "    recdict_rand = pickle.load(open(frand, 'rb'))\n",
    "    recdict_ijcai = pickle.load(open(fijcai, 'rb'))\n",
    "    \n",
    "    return recdict_rank, recdict_tran, recdict_comb, recdict_rand, recdict_ijcai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate F1-scores from loaded results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_rand, recdict_ijcai, func):\n",
    "    assert(isinstance(func, types.FunctionType))\n",
    "    \n",
    "    # deal with missing values: \n",
    "    # get rid of recommendation that not all method are successful, \n",
    "    # due to ILP timeout, <start, end> of test doesn't exist in training set.\n",
    "    assert(np.all(sorted(recdict_rank.keys()) == sorted(recdict_tran.keys())))\n",
    "    assert(np.all(sorted(recdict_rank.keys()) == sorted(recdict_comb.keys())))\n",
    "    \n",
    "    keys_all = sorted(recdict_ijcai.keys() & recdict_rank.keys())\n",
    "    \n",
    "    # compute F1\n",
    "    rank1 = []  # rank pop\n",
    "    rank2 = []  # rank feature\n",
    "    #for key in sorted(recdict_rank.keys()):\n",
    "    for key in keys_all:\n",
    "        rank1.append(func(recdict_rank[key]['REAL'], recdict_rank[key]['REC_POP']))\n",
    "        rank2.append(func(recdict_rank[key]['REAL'], recdict_rank[key]['REC_FEATURE']))\n",
    "    \n",
    "    tran1 = []  # transition DP\n",
    "    tran2 = []  # transition ILP\n",
    "    #for key in sorted(recdict_tran.keys()):\n",
    "    for key in keys_all:\n",
    "        tran1.append(func(recdict_tran[key]['REAL'], recdict_tran[key]['REC_DP']))\n",
    "        tran2.append(func(recdict_tran[key]['REAL'], recdict_tran[key]['REC_ILP']))\n",
    "\n",
    "    comb1 = []  # combine rank and transition DP\n",
    "    comb2 = []  # combine rank and transition ILP\n",
    "    #for key in sorted(recdict_comb.keys()):\n",
    "    for key in keys_all:\n",
    "        comb1.append(func(recdict_comb[key]['REAL'], recdict_comb[key]['REC_DP']))\n",
    "        comb2.append(func(recdict_comb[key]['REAL'], recdict_comb[key]['REC_ILP']))\n",
    "            \n",
    "    rand = []   # structured prediction\n",
    "    #for key in sorted(recdict_rand.keys()):\n",
    "    for key in keys_all:\n",
    "        rand.append(func(recdict_rand[key]['REAL'], recdict_rand[key]['REC_RAND']))\n",
    "    \n",
    "    ijcai05T = []   # IJCAI method\n",
    "    #ijcai10T = []   # IJCAI method\n",
    "    ijcai05L = []   # IJCAI method\n",
    "    #ijcai10L = []   # IJCAI method\n",
    "    #for key in sorted(recdict_ijcai.keys()):\n",
    "    for key in keys_all:\n",
    "        #if func == calc_F1:\n",
    "        #    ijcai05T.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC05T']))\n",
    "            #ijcai10T.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC10T']))\n",
    "        ijcai05T.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC05T']))\n",
    "        ijcai05L.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC05L']))\n",
    "        #ijcai10L.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC10L']))        \n",
    "    \n",
    "    # compute mean and std of F1\n",
    "    metrics = [rand]\n",
    "    #if func == calc_F1:\n",
    "    #    metrics = metrics + [ijcai05T]\n",
    "    metrics = metrics + [ijcai05T]\n",
    "    metrics = metrics + [ijcai05L, rank1, rank2, tran1, tran2, comb1, comb2]\n",
    "    means = [np.mean(x) for x in metrics]\n",
    "    stds  = [np.std(x)  for x in metrics]\n",
    "    \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Latex tables from calculated metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_latex_table(mean_df, std_df, ismax_df, ismax2nd_df, type_ix, title, label):    \n",
    "    strs = []\n",
    "    strs.append('\\\\begin{table*}[t]\\n')\n",
    "    strs.append('\\\\caption{' + title + '}\\n')\n",
    "    strs.append('\\\\label{' + label + '}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    #strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{l|' + (mean_df.shape[1])*'c' + '} \\\\hline\\n')\n",
    "    for col in mean_df.columns:\n",
    "        strs.append(' & ' + col)\n",
    "    strs.append(' \\\\\\\\ \\\\hline\\n')\n",
    "    for ix in mean_df.index:\n",
    "        for j in range(mean_df.shape[1]):\n",
    "            if j == 0: strs.append(ix + ' ')\n",
    "            jx = mean_df.columns[j]\n",
    "            strs.append('& $')\n",
    "            if ismax_df.loc[ix, jx] == True: strs.append('\\\\mathbf{')\n",
    "            if ismax2nd_df.loc[ix, jx] == True: strs.append('\\\\mathit{')\n",
    "            strs.append('%.3f' % mean_df.loc[ix, jx] + '\\\\pm' + '%.3f' % std_df.loc[ix, jx])\n",
    "            if ismax_df.loc[ix, jx] == True or ismax2nd_df.loc[ix, jx] == True: strs.append('}')\n",
    "            strs.append('$ ')\n",
    "        strs.append('\\\\\\\\\\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\end{table*}\\n')\n",
    "    return ''.join(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate evaluation data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "func = calc_F1\n",
    "#func = calc_pairsF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#if func == calc_Tau: \n",
    "#    methods = [methods_all[0]] + methods_all[2:]\n",
    "#else:\n",
    "#    methods = methods_all.copy()   \n",
    "methods = methods_all.copy() \n",
    "\n",
    "for type_ix in range(len(dat_types)):\n",
    "    mean_df = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                           columns=dat_names, index=methods)\n",
    "    std_df  = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                           columns=dat_names, index=methods)\n",
    "        \n",
    "    for dat_ix in range(len(dat_suffix)):\n",
    "        recdict_rank, recdict_tran, recdict_comb, recdict_rand, recdict_ijcai = load_results(dat_ix, type_ix)\n",
    "        means, stds = calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_rand, recdict_ijcai, func)\n",
    "        #print(len(means), len(stds), len(methods))\n",
    "        assert(len(means) == len(stds) == len(methods))\n",
    "        mean_df[dat_names[dat_ix]] = means\n",
    "        std_df[dat_names[dat_ix]]  = stds\n",
    "        \n",
    "    ismax_df  = pd.DataFrame(data=np.zeros(mean_df.shape, dtype=np.bool), columns=mean_df.columns, index=mean_df.index)\n",
    "    ismax2nd_df = ismax_df.copy()\n",
    "    for col in ismax_df.columns:\n",
    "        #maxix = mean_df[col].argmax()\n",
    "        #ismax_df.loc[maxix, col] = True\n",
    "        indices = (-mean_df[col]).argsort().values[:2]\n",
    "        ismax_df.iloc[indices[0]][col] = True\n",
    "        ismax2nd_df.iloc[indices[1]][col] = True\n",
    "    \n",
    "    if func == calc_F1:\n",
    "        title = '''Performance comparison on five datasets in terms of trajectory F$_1$ score. \n",
    "        The best method for each dataset (i.e., a column) is shown in bold, the second best is shown in italic.'''\n",
    "        label = 'tab:f1'\n",
    "    else:\n",
    "        title = '''Performance comparison on five datasets in terms of pairs-F$_1$.\n",
    "        The best method for each dataset (i.e., a column) is shown in bold, the second best is shown in italic.'''\n",
    "        label = 'tab:pairf1'\n",
    "    strs = gen_latex_table(mean_df, std_df, ismax_df, ismax2nd_df, type_ix, title, label)\n",
    "    #mean_df.to_csv('pf1_new.csv')\n",
    "    \n",
    "    print(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the difference between the new performance table and the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#F1new = pd.read_csv('f1_new.csv')\n",
    "#F1new.drop(F1new.columns[0], axis=1, inplace=True)\n",
    "#F1new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#F1old = pd.read_csv('f1_old.csv')\n",
    "#F1old.drop(F1old.columns[0], axis=1, inplace=True)\n",
    "#F1old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#F1diff = pd.DataFrame(data=(F1new-F1old).values, columns=dat_names, index=methods_all)\n",
    "#zero_df = pd.DataFrame(data=np.zeros(F1diff.shape), columns=dat_names, index=methods_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(gen_latex_table(F1diff, zero_df, zero_df, zero_df, 0, uspecific, 'F1 improvement', 'tab:f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pF1new = pd.read_csv('pf1_new.csv')\n",
    "#pF1new.drop(pF1new.columns[0], axis=1, inplace=True)\n",
    "#pF1new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pF1old = pd.read_csv('pf1_old.csv')\n",
    "#pF1old.drop(pF1old.columns[0], axis=1, inplace=True)\n",
    "#pF1old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pF1diff = pd.DataFrame(data=(pF1new-pF1old).values, columns=dat_names, index=methods_all)\n",
    "#zero_df = pd.DataFrame(data=np.zeros(pF1diff.shape), columns=dat_names, index=methods_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(gen_latex_table(pF1diff, zero_df, zero_df, zero_df, 0, uspecific, 'pairs-F1 improvement', 'tab:pf1'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
