{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Book for Trajectory Recommendation Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label effects on SSVM and RankSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some thoughts:\n",
    "- Multi-label hurts SSVM as we have multiple labels given an example (a feature vector).\n",
    "- On the other hand, as the label of example (a POI and query specific feature vector) for RankSVM is computed by counting the number of occurrence of the POI in trajectories that conform to the query, it seems there's no multi-label problem in RankSVM training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**\n",
    "- Experiment on generated dataset (single label for an example/query)\n",
    "- Both POI and transition features are scaled linearly to $(-1,1)$ using MinMaxScaler\n",
    "- $C$ is tuned using Monte-Carlo CV at the beginning and keeped the same for all leave-one-out CV\n",
    "- $C$ for SSVM, SSVM without transition features and the $C$ for RankSVM are tunned seperatly\n",
    "- Prediction inference in SSVM is the list Viterbi algorithm\n",
    "- This experiment is performed in notebook ```generated_data.ipynb```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "- When features are computed from the original dataset (with duration related features), NOT the generated dataset, SSVM performs better than RankSVM, sample results:\n",
    "```\n",
    "RankSVM:           F1 (0.597, 0.011), pairsF1 (0.248, 0.012), Tau (0.507, 0.011)\n",
    "SSVM:              F1 (0.883, 0.014), pairsF1 (0.667, 0.027), Tau (0.843, 0.017)\n",
    "SSVM-NoTransition: F1 (0.827, 0.015), pairsF1 (0.510, 0.021), Tau (0.775, 0.015)\n",
    "```\n",
    "- When features are recomputed from the generated dataset (so NO duration related features), RankSVM performs better than SSVM, sample results:\n",
    "```\n",
    "RankSVM:           F1 (0.903, 0.012), pairsF1 (0.612, 0.023), Tau (0.858, 0.013)\n",
    "SSVM:              F1 (0.865, 0.016), pairsF1 (0.607, 0.026), Tau (0.822, 0.017)\n",
    "SSVM-NoTransition: F1 (0.869, 0.017), pairsF1 (0.589, 0.026), Tau (0.819, 0.018) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**\n",
    "- Scale transition features, i.e. the log probabilities factorised according to a number of features, to range $(-1,1)$ linearly.\n",
    "- The Osaka dataset is used and the performance is evaluated using leave-one-out cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSVM with RankSVM weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment** \n",
    "- This experiment plug the weights of a trained RankSVM, i.e. a vector $w$ and $|w|$ is the number of POI (and query) features, in SSVM and do prediction, this means we ignore transition features and tie weights among different POIs.\n",
    "- A dedicated notebook ```ssvm_ranksvm_weights.ipynb``` is created for this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** \n",
    "- We found that SSVM with RankSVM weights performance very similar to RankSVM, in fact, when using the list Viterbi algorithm, the predicted trajectory given any query (in leave-one-out cross validation) contains the exactly same set of POIs as the predition by RankSVM, except the visiting order of these POIs is different.\n",
    "- Features are scaled using **MinMaxScaler** (scikit-learn), and scaled to range $(-1,1)$ linearly, which is the scaling method used in RankSVM (the libsvm implementation).\n",
    "- Sample results:\n",
    "```\n",
    "As POI features for both RankSVM and SSVM are the same, so we can use the inference procedure of SSVM with RankSVM weights. (All transition features are set to zero)\n",
    "The weights of RankSVM are computed from the leave-one-out, i.e., a vector of weights for each query in training set.\n",
    "The dataset used here is Glasgow.\n",
    "The performance of RankSVM:\n",
    "F1 (0.767, 0.026), pairsF1 (0.553, 0.047), Tau (0.739, 0.030)\n",
    "The performance of SSVM using the weights of the above RankSVM:\n",
    "SSVM-Viterbi: F1 (0.713, 0.032), pairsF1 (0.575, 0.046), Tau (0.740, 0.031)\n",
    "SSVM-listViterbi: F1 (0.765, 0.026), pairsF1 (0.550, 0.046), Tau (0.739, 0.030)\n",
    "```\n",
    "- When the **MaxAbsScaler** was used, SSVM performed much worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSVM vs RankSVM on generated dataset (Check if multi-label hurts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**\n",
    "- POI features and transition features are computed on Glasgow dataset, trajectories (i.e., labels) are from generated dataset (#trajectories=125).\n",
    "- POI and transition features are computed from generated data (NO duration related features)\n",
    "- Performance are evaluated using leave-one-out cross validation.\n",
    "- Regularisation parameter $C$ are tuned using Monte-Carlo cross validation at the beginning, then the same $C$ was used for all leave-one-out cross validations.\n",
    "- Prediction inference in SSVM is the list Viterbi algorithm\n",
    "- A dedicated notebook ```generated_data.ipynb``` is created for this experiment.\n",
    "\n",
    "**Conclusion**\n",
    "- Neither SSVM nor RankSVM can achieve nearly perfect performance, which mean multi-label problem hurt both models.\n",
    "- RankSVM performs better than SSVM.\n",
    "- Sample results:\n",
    "```\n",
    "SSVM:    F1 (0.699, 0.015), pairsF1 (0.416, 0.021), Tau (0.643, 0.016)\n",
    "RankSVM: F1 (0.881, 0.011), pairsF1 (0.572, 0.019), Tau (0.829, 0.012)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
