{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Book for Trajectory Recommendation Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment to check something\n",
    "\n",
    "#### Conjecture\n",
    "\n",
    "#### Experiment\n",
    "\n",
    "#### Results\n",
    "\n",
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RankSVM with different features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unary features: \n",
    " 1. category: one-hot encoding of POI category, encode True as 1 and False as -1\n",
    " 1. neighbourhood: one-hot encoding of POI cluster, encode True as 1 and False as -1\n",
    " 1. popularity: log of POI popularity, i.e., the number of distinct users that visited the POI\n",
    " 1. nVisit: log of the total number of visit by all users\n",
    " 1. avgDuration: log of average POI visit duration\n",
    "\n",
    "- Derived features:\n",
    " 1. trajLen: trajectory length, i.e., the number of POIs nPOI in trajectory, copy from query\n",
    " 1. sameCatStart: 1 if POI category is the same as that of startPOI, -1 otherwise\n",
    " 1. distStart: distance (haversine formula) from startPOI\n",
    " 1. diffPopStart: difference in POI popularity from startPOI (NO LOG as it could be negative)\n",
    " 1. diffNVisitStart: difference in the total number of visit from startPOI\n",
    " 1. diffDurationStart: difference in average POI visit duration from the actual duration spent at startPOI\n",
    " 1. sameNeighbourhoodStart: 1 if POI resides in the same cluster as that of startPOI, -1 otherwise\n",
    "\n",
    "Glasgow:\n",
    "```\n",
    "Unary+Derived: F1 (0.764, 0.027), pairsF1 (0.550, 0.047), Tau (0.736, 0.030)\n",
    "Unary:         F1 (0.659, 0.030), pairsF1 (0.388, 0.049), Tau (0.624, 0.033)\n",
    "```\n",
    "\n",
    "Toronto:\n",
    "```\n",
    "Unary+Derived: \n",
    "Unary:         F1 (0.676, 0.021), pairsF1 (0.370, 0.033), Tau (0.629, 0.023)\n",
    "```\n",
    "\n",
    "Osaka:\n",
    "```\n",
    "Unary+Derived: F1 (0.678, 0.037), pairsF1 (0.425, 0.058), Tau (0.646, 0.040)\n",
    "Unary:         F1 (0.622, 0.033), pairsF1 (0.307, 0.053), Tau (0.590, 0.035)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-user multi-label SSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formulation\n",
    "We would like to formulate a multi-user multi-label SSVM as\n",
    "\\begin{align}\n",
    "\\min_{\\mathbf{w},\\xi\\ge0} ~& \\frac{1}{2m} \\sum_{i=1}^m \\|\\mathbf{w}_i - \\bar{\\mathbf{w}}\\|^2 + \n",
    "                             C \\sum_i \\sum_j \\sum_k \\xi_{ijk} \\\\\n",
    "s.t. ~& \\langle \\mathbf{w}_i, \\Psi(\\mathbf{x}_{ij}, \\mathbf{y}_{ijk}) \\rangle -  \n",
    "        \\langle \\mathbf{w}_i, \\Psi(\\mathbf{x}_{ij}, \\bar{\\mathbf{y}}) \\rangle \\ge \n",
    "        \\Delta(\\mathbf{y}_{ijk}, \\bar{\\mathbf{y}}) - \\xi_{ijk},~\n",
    "        \\bar{\\mathbf{y}} \\in \\mathcal{Y} \\setminus \\{\\mathbf{y}_{ijk}\\}_{k=1}^{m_{ij}},~\n",
    "        \\forall k,~\\forall j,~\\forall i.\n",
    "\\end{align}\n",
    "where $i$ indexes users, $j$ indexes queries of the $i$-th user and $k$ indexes the (multi-) labels of the $j$-th query of the $i$-th user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawback\n",
    "- The standard form of quadratic program (QP) is\n",
    "  \\begin{align}\n",
    "   \\min_{x}~& \\frac{1}{2}x^\\top P x + q^\\top x \\\\\n",
    "   s.t. ~& G x \\le h \\\\\n",
    "          & A x = b\n",
    "  \\end{align}\n",
    "- It seems that the regularisation term $\\sum_{i=1}^m \\|w_i - \\bar{w}\\|^2$ where $\\bar{w} = \\frac{1}{m} \\sum_{i=1}^m w_i$ can not be rephrased into the standard form of QP objective.\n",
    "- As pystruct solve the dual problem (QP) of the 1-slack SSVM (primal), however, in the Wolfe-Dual of the multi-user multi-label 1-slack SSVM (the former was shown in the appendix of [Cutting-Plane Training of Structural SVMs](https://www.cs.cornell.edu/people/tj/publications/joachims_etal_09a.pdf)), its objective contains both dual variables and primal variables, which is NOT a QP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single label SSVM training: Viterbi vs List Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjecture\n",
    "SSVM can be trained better if the list Viterbi algorithm (instead of the Viterbi algorithm) is used to do the loss augmented inference.\n",
    "\n",
    "#### Experiment\n",
    "- Train a *single label* SSVM on Osaka dataset, use the list Viterbi algorithm to do the prediction inference.\n",
    "- Use the Viterbi algorithm and the list Viterbi algorithm to do the loss augmented inference, respectively.\n",
    "- SSVM *without parameter sharing*, and *take the log* of transitions features (factorised probabilities).\n",
    "- Evaluate the performance by the leave-one-out cross validation with regularisation constant $C$ tuned using the Monte-Carlo cross validation.\n",
    "\n",
    "#### Results\n",
    "- `SSVM-V-LV-SL`: single label SSVM, loss augmented inference: Viterbi, prediction inference: list Viterbi\n",
    "- `SSVM-LV-LV-SL`: single label SSVM, loss augmented inference: list Viterbi, prediction inference: list Viterbi\n",
    "- Larger datasets (that Osaka) are computationally too expensive.\n",
    "\n",
    "```\n",
    "SSVM-V-LV-SL:\n",
    "F1 (0.632, 0.041), pairsF1 (0.386, 0.061), Tau (0.603, 0.044), perfectF1: 13/46, perfectPairsF1: 13/46\n",
    "\n",
    "SSVM-LV-LV-SL:\n",
    "F1 (0.557, 0.036), pairsF1 (0.249, 0.055), Tau (0.523, 0.038), perfectF1:  8/46, perfectPairsF1: 8/46\n",
    "```\n",
    "\n",
    "#### Conclusion\n",
    "The conjecture is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label SSVM on larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjecture\n",
    "Multi-label SSVM can compete with RankSVM.\n",
    "\n",
    "#### Experiment\n",
    "Do leave-one-out cross validation of multi-label SSVM (`SSVM-ML`) and rankSVM (as well as single-label SSVM `SSVM-SL`) on Glasgow and Toronto dataset. Note that here query is $(s, K)$ and we share parameters among POIs/transitions, besides, we do NOT take the log of transitions features (factorised probabilities).\n",
    "\n",
    "#### Results\n",
    "```\n",
    "Glasgow:\n",
    "RankSVM: F1 (0.767, 0.026), pairsF1 (0.553, 0.047), Tau (0.739, 0.030), perfectF1: 25/64, perfectPairsF1: 25/64\n",
    "SSVM-ML: F1 (0.752, 0.028), pairsF1 (0.532, 0.048), Tau (0.721, 0.031), perfectF1: 25/64, perfectPairsF1: 22/64\n",
    "SSVM-SL: F1 (0.629, 0.031), pairsF1 (0.362, 0.047), Tau (0.589, 0.034), perfectF1: 15/64, perfectPairsF1: 15/64\n",
    "\n",
    "Osaka:\n",
    "RankSVM: F1 (0.678, 0.037), pairsF1 (0.433, 0.059), Tau (0.647, 0.040), perfectF1: 15/46, perfectPairsF1: 14/46\n",
    "SSVM-ML: F1 (0.670, 0.040), pairsF1 (0.433, 0.060), Tau (0.637, 0.044), perfectF1: 15/46, perfectPairsF1: 14/46\n",
    "SSVM-SL: F1 (0.599, 0.033), pairsF1 (0.292, 0.052), Tau (0.566, 0.036), perfectF1: 8/46,  perfectPairsF1: 8/46\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label stats for queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjecture\n",
    "Only a small fraction of users have more than one label for a given query.\n",
    "\n",
    "#### Experiment\n",
    "Design a new query $(s, K, u)$ where\n",
    "- `s`: start POI of a trajectory\n",
    "- `K`: the number of desired POIs\n",
    "- `u`: user ID\n",
    "then check how many of these queries have multi-labels.\n",
    "\n",
    "#### Results\n",
    "when query is $(s, K, u)$, \n",
    "`(#queries with multi-label) / (total #queries)`\n",
    "```\n",
    "Osaka:     4/181   ~2%\n",
    "Glasgow:   18/325  ~6%\n",
    "Edinburgh: 78/1260 ~6%\n",
    "Toronto:   68/813  ~8%\n",
    "Melbourne: 39/965  ~4%\n",
    "```\n",
    "and if the query contains only $(s, K)$, the fraction of multi-labels are:\n",
    "```\n",
    "Osaka:     30/47   ~64%\n",
    "Glasgow:   41/64   ~64%\n",
    "Edinburgh: 104/147 ~71%\n",
    "Toronto:   69/99   ~70%\n",
    "Melbourne: 139/280 ~50%\n",
    "```\n",
    "Lastly, if the query is $(s, u)$, the fraction of multi-labels are:\n",
    "```\n",
    "Osaka:     8/177    ~5%\n",
    "Glasgow:   29/309   ~9%\n",
    "Edinburgh: 121/1165 ~10%\n",
    "Toronto:   79/751   ~11%\n",
    "Melbourne: 69/925   ~7%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label SSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**\n",
    "- Implement multi-label SSVM, and compare the performance with vanilla SSVM\n",
    "- For multi-label SSVM, use the list Viteri algorithm to do both loss_augmented_inference and inference for prediction\n",
    "- Leave-one-out evaluation on Osaka dataset\n",
    "- This experiment is performed in notebook `ssvm_ml.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "- Sample results on Osaka dataset\n",
    " - `Tie-Log`: share parameters among POIs and transitions, and take the log of (factorised) transition probabilities\n",
    " - `Tie-NoLog`: share parameters among POIs and transitions, but do NOT take the log of (factorised) transition probabilities\n",
    " - `NoTie-Log`: do NOT share parameters among POIs and transitions, and take the log of (factorised) transition probabilities\n",
    " - `NoTie-NoLog`: do NOT share parameters among POIs and transitions, and do NOT take the log of (factorised) transition probabilities\n",
    " ```\n",
    " SSVM-MultiLabel-Tie-Log:     F1 (0.624, 0.038), pairsF1 (0.363, 0.059), Tau (0.591, 0.042)\n",
    " SSVM-MultiLabel-Tie-NoLog:   F1 (0.659, 0.040), pairsF1 (0.423, 0.060), Tau (0.626, 0.044)\n",
    " SSVM-MultiLabel-NoTie-NoLog: F1 (0.649, 0.035), pairsF1 (0.373, 0.057), Tau (0.619, 0.038)\n",
    " SSVM-MultiLabel-NoTie-Log:   F1 (0.655, 0.035), pairsF1 (0.377, 0.057), Tau (0.624, 0.037)\n",
    " SSVM-Tie-Log:                F1 (0.611, 0.037), pairsF1 (0.339, 0.058), Tau (0.580, 0.040)\n",
    " SSVM-Tie-NoLog:              F1 (0.613, 0.037), pairsF1 (0.330, 0.057), Tau (0.579, 0.041) \n",
    " SSVM-NoTie-NoLog:            F1 (0.637, 0.039), pairsF1 (0.378, 0.061), Tau (0.605, 0.043)\n",
    " SSVM-NoTie-Log:              F1 (0.626, 0.039), pairsF1 (0.361, 0.060), Tau (0.593, 0.042)\n",
    " RankSVM:                     F1 (0.678, 0.037), pairsF1 (0.433, 0.059), Tau (0.647, 0.040)\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning real dataset to create a single label dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**\n",
    "- Pruning the Glasgow dataset $\\mathcal{M}_0$, and keep only one trajectory for each query with regards to some deterministic method to choose which trajectory should be keeped among trajectories that conform to the query. (e.g., the one with maximum total number of POI popularity etc.), let $\\mathcal{M}_1$ be the new dataset\n",
    "- Train SSVM and RankSVM on $\\mathcal{M}_1$, features are computed from $\\mathcal{M}_0$ or $\\mathcal{M}_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "- Sample results:\n",
    " - Features are computed on the $\\mathcal{M}_0$\n",
    " ```\n",
    " RankSVM:           F1 (0.536, 0.017), pairsF1 (0.145, 0.020), Tau (0.484, 0.018)\n",
    " SSVM:              F1 (0.612, 0.029), pairsF1 (0.317, 0.047), Tau (0.573, 0.032)\n",
    " SSVM-NoTransition: F1 (0.610, 0.029), pairsF1 (0.309, 0.044), Tau (0.571, 0.032)\n",
    " ```\n",
    " - Features are computed on the $\\mathcal{M}_1$\n",
    " ```\n",
    " RankSVM:           F1 (0.705, 0.030), pairsF1 (0.414, 0.047), Tau (0.667, 0.033)\n",
    " SSVM:              F1 (0.629, 0.029), pairsF1 (0.334, 0.046), Tau (0.588, 0.032)\n",
    " SSVM-NoTransition: F1 (0.588, 0.026), pairsF1 (0.265, 0.040), Tau (0.546, 0.029)\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Trajectories using SSVM with random weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**\n",
    "- Features are computed from Glasgow dataset $\\mathcal{M}_0$\n",
    "- SSVM weights are random samples from a standard univariate Gaussian distribution `numpy.random.randn()`\n",
    "- Prediction inference of SSVM is the list Viterbi algorithm, generated dataset $\\mathcal{M}_1$\n",
    "- Use leave-one-evaluation to evaluate performance (features are computed from $\\mathcal{M}_1$ and labels are from $\\mathcal{M}_1$)\n",
    "- This experiment is performed in notebook ```generated_data.ipynb```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "- The number of visit for POI are concentrate on a small subset of POIs\n",
    "- The transition matrix of the number of visit (discretized) compute from $\\mathcal{M}_1$ is similar to that from $\\mathcal{M}_0$\n",
    "- The transition features are correlated with POI features (as transition matrix are factorised according to several POI features)\n",
    "- It could be that both the POI features and transition features are good, but transition features don't provide new information (Cheng)\n",
    "- Sample results from $3$ runs (each run with a different random weights, thus different $\\mathcal{M}_1$)\n",
    "```\n",
    "SSVM: F1 (0.812, 0.016), pairsF1 (0.574, 0.028), Tau (0.757, 0.019)\n",
    "SSVM: F1 (0.745, 0.018), pairsF1 (0.500, 0.029), Tau (0.697, 0.020)\n",
    "SSVM: F1 (0.772, 0.019), pairsF1 (0.544, 0.030), Tau (0.726, 0.021)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label effects on SSVM and RankSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some thoughts:\n",
    "- Multi-label hurts SSVM as we have multiple labels given an example (a feature vector).\n",
    "- On the other hand, as the label of example (a POI and query specific feature vector) for RankSVM is computed by counting the number of occurrence of the POI in trajectories that conform to the query, it seems there's no multi-label problem in RankSVM training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**\n",
    "- Experiment on generated dataset (single label for an example/query)\n",
    "- Both POI and transition features are scaled linearly to $(-1,1)$ using MinMaxScaler\n",
    "- $C$ is tuned using Monte-Carlo CV at the beginning and keeped the same for all leave-one-out CV\n",
    "- $C$ for SSVM, SSVM without transition features and the $C$ for RankSVM are tunned seperatly\n",
    "- Prediction inference in SSVM is the list Viterbi algorithm\n",
    "- This experiment is performed in notebook ```generated_data.ipynb```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "- When features are computed from the original dataset (with duration related features), NOT the generated dataset, SSVM performs better than RankSVM, sample results:\n",
    "```\n",
    "RankSVM:           F1 (0.597, 0.011), pairsF1 (0.248, 0.012), Tau (0.507, 0.011)\n",
    "SSVM:              F1 (0.883, 0.014), pairsF1 (0.667, 0.027), Tau (0.843, 0.017)\n",
    "SSVM-NoTransition: F1 (0.827, 0.015), pairsF1 (0.510, 0.021), Tau (0.775, 0.015)\n",
    "```\n",
    "- When features are recomputed from the generated dataset (so NO duration related features), RankSVM performs better than SSVM, sample results:\n",
    "```\n",
    "RankSVM:           F1 (0.903, 0.012), pairsF1 (0.612, 0.023), Tau (0.858, 0.013)\n",
    "SSVM:              F1 (0.865, 0.016), pairsF1 (0.607, 0.026), Tau (0.822, 0.017)\n",
    "SSVM-NoTransition: F1 (0.869, 0.017), pairsF1 (0.589, 0.026), Tau (0.819, 0.018) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**\n",
    "- Scale transition features, i.e. the log probabilities factorised according to a number of features, to range $(-1,1)$ linearly.\n",
    "- The Osaka dataset is used and the performance is evaluated using leave-one-out cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSVM with RankSVM weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment** \n",
    "- This experiment plug the weights of a trained RankSVM, i.e. a vector $w$ and $|w|$ is the number of POI (and query) features, in SSVM and do prediction, this means we ignore transition features and tie weights among different POIs.\n",
    "- A dedicated notebook ```ssvm_ranksvm_weights.ipynb``` is created for this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** \n",
    "- We found that SSVM with RankSVM weights performance very similar to RankSVM, in fact, when using the list Viterbi algorithm, the predicted trajectory given any query (in leave-one-out cross validation) contains the exactly same set of POIs as the predition by RankSVM, except the visiting order of these POIs is different.\n",
    "- Features are scaled using **MinMaxScaler** (scikit-learn), and scaled to range $(-1,1)$ linearly, which is the scaling method used in RankSVM (the libsvm implementation).\n",
    "- Sample results:\n",
    "```\n",
    "As POI features for both RankSVM and SSVM are the same, so we can use the inference procedure of SSVM with RankSVM weights. (All transition features are set to zero)\n",
    "The weights of RankSVM are computed from the leave-one-out, i.e., a vector of weights for each query in training set.\n",
    "The dataset used here is Glasgow.\n",
    "The performance of RankSVM:\n",
    "F1 (0.767, 0.026), pairsF1 (0.553, 0.047), Tau (0.739, 0.030)\n",
    "The performance of SSVM using the weights of the above RankSVM:\n",
    "SSVM-Viterbi: F1 (0.713, 0.032), pairsF1 (0.575, 0.046), Tau (0.740, 0.031)\n",
    "SSVM-listViterbi: F1 (0.765, 0.026), pairsF1 (0.550, 0.046), Tau (0.739, 0.030)\n",
    "```\n",
    "- When the **MaxAbsScaler** was used, SSVM performed much worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSVM vs RankSVM on generated dataset (Check if multi-label hurts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment**\n",
    "- POI features and transition features are computed on Glasgow dataset, trajectories (i.e., labels) are from generated dataset (#trajectories=125).\n",
    "- POI and transition features are computed from generated data (NO duration related features)\n",
    "- Performance are evaluated using leave-one-out cross validation.\n",
    "- Regularisation parameter $C$ are tuned using Monte-Carlo cross validation at the beginning, then the same $C$ was used for all leave-one-out cross validations.\n",
    "- Prediction inference in SSVM is the list Viterbi algorithm\n",
    "- A dedicated notebook ```generated_data.ipynb``` is created for this experiment.\n",
    "\n",
    "**Conclusion**\n",
    "- Neither SSVM nor RankSVM can achieve nearly perfect performance, which mean multi-label problem hurt both models.\n",
    "- RankSVM performs better than SSVM.\n",
    "- Sample results:\n",
    "```\n",
    "SSVM:    F1 (0.699, 0.015), pairsF1 (0.416, 0.021), Tau (0.643, 0.016)\n",
    "RankSVM: F1 (0.881, 0.011), pairsF1 (0.572, 0.019), Tau (0.829, 0.012)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
