{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-one-out Evaluation of SSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave-one-query-out evaluation of (single-/multi-label) SSVM with regularisation parameter $C$ tuned using Monte-Carlo cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyximport; pyximport.install()\n",
    "from inference_lv import do_inference_list_viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from inference import do_inference_brute_force, do_inference_viterbi\n",
    "from shared import TrajData\n",
    "from ssvm import SSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(1234554321)\n",
    "np.random.seed(123456789)\n",
    "cvxopt.base.setseed(123456789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_ix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_obj = TrajData(dat_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_JOBS = 6         # number of parallel jobs\n",
    "C_SET = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000, 3000]  # regularisation parameter\n",
    "MC_PORTION = 0.1   # the portion of data that sampled by Monte-Carlo cross-validation\n",
    "MC_NITER = 5       # number of iterations for Monte-Carlo cross-validation\n",
    "SSVM_SHARE_PARAMS = True  # share params among POIs/transitions in SSVM\n",
    "SSVM_MULTI_LABEL = True  # use multi-label SSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested cross-validation with Monte-Carlo cross-validation as inner loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inference_methods = [do_inference_brute_force, do_inference_list_viterbi, do_inference_viterbi]\n",
    "methods_suffix = ['bruteForce', 'listViterbi', 'viterbi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_ix = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recdict_ssvm = dict()\n",
    "cnt = 1\n",
    "keys = sorted(dat_obj.TRAJ_GROUP_DICT.keys())\n",
    "\n",
    "# outer loop to evaluate the test performance by cross validation\n",
    "for i in range(len(keys)):\n",
    "    ps, L = keys[i]\n",
    "    best_C = 1\n",
    "    #best_F1 = 0; best_pF1 = 0\n",
    "    best_Tau = 0\n",
    "    keys_cv = keys[:i] + keys[i+1:]\n",
    "    \n",
    "    # use all training+validation set to compute POI features, \n",
    "    # make sure features do NOT change for training and validation\n",
    "    trajid_set_i = set(dat_obj.trajid_set_all) - dat_obj.TRAJ_GROUP_DICT[keys[i]]\n",
    "    poi_info_i = dat_obj.calc_poi_info(list(trajid_set_i))\n",
    "    \n",
    "    poi_set_i = {p for tid in trajid_set_i for p in dat_obj.traj_dict[tid] if len(dat_obj.traj_dict[tid]) >= 2}\n",
    "    if ps not in poi_set_i: \n",
    "        sys.stderr.write('start POI of query %s does not exist in training set.\\n' % str(keys[i]))\n",
    "        continue\n",
    "    \n",
    "    # tune regularisation constant C\n",
    "    for ssvm_C in C_SET:\n",
    "        print('\\n--------------- try_C: %f ---------------\\n' % ssvm_C); sys.stdout.flush() \n",
    "        F1_ssvm = []; pF1_ssvm = []; Tau_ssvm = []        \n",
    "        \n",
    "        # inner loop to evaluate the performance of a model with a specified C by Monte-Carlo cross validation\n",
    "        for j in range(MC_NITER):\n",
    "            poi_list = []\n",
    "            while True: # make sure the start POI in test set are also in training set\n",
    "                rand_ix = np.arange(len(keys_cv)); np.random.shuffle(rand_ix)\n",
    "                test_ix = rand_ix[:int(MC_PORTION*len(rand_ix))]\n",
    "                assert(len(test_ix) > 0)\n",
    "                trajid_set_train = set(dat_obj.trajid_set_all) - dat_obj.TRAJ_GROUP_DICT[keys[i]]\n",
    "                for j in test_ix: \n",
    "                    trajid_set_train = trajid_set_train - dat_obj.TRAJ_GROUP_DICT[keys_cv[j]]\n",
    "                poi_set = {p for tid in sorted(trajid_set_train) for p in dat_obj.traj_dict[tid] \\\n",
    "                           if len(dat_obj.traj_dict[tid]) >= 2}\n",
    "                good_partition = True\n",
    "                for j in test_ix: \n",
    "                    if keys_cv[j][0] not in poi_set: good_partition = False; break\n",
    "                if good_partition == True: \n",
    "                    poi_list = sorted(poi_set)\n",
    "                    break\n",
    "\n",
    "            # train\n",
    "            ssvm = SSVM(inference_train=inference_methods[method_ix], inference_pred=inference_methods[method_ix], \n",
    "                        dat_obj=dat_obj, share_params=SSVM_SHARE_PARAMS, multi_label=SSVM_MULTI_LABEL, \n",
    "                        C=ssvm_C, poi_info=poi_info_i.loc[poi_list].copy())\n",
    "            if ssvm.train(sorted(trajid_set_train), n_jobs=N_JOBS) == True:            \n",
    "                for j in test_ix: # test\n",
    "                    ps_cv, L_cv = keys_cv[j]\n",
    "                    y_hat = ssvm.predict(ps_cv, L_cv)\n",
    "                    if y_hat is not None:\n",
    "                        F1, pF1, tau = dat_obj.evaluate(keys_cv[j], y_hat)\n",
    "                        F1_ssvm.append(F1); pF1_ssvm.append(pF1); Tau_ssvm.append(tau)\n",
    "            else: \n",
    "                for j in test_ix:\n",
    "                    F1_ssvm.append(0); pF1_ssvm.append(0); Tau_ssvm.append(0)\n",
    "        \n",
    "        #mean_F1 = np.mean(F1_ssvm); mean_pF1 = np.mean(pF1_ssvm)\n",
    "        mean_Tau = np.mean(Tau_ssvm)\n",
    "        print('mean_Tau: %.3f' % mean_Tau)\n",
    "        if mean_Tau > best_Tau:\n",
    "            best_Tau = mean_Tau\n",
    "            best_C = ssvm_C\n",
    "    print('\\n--------------- %d/%d, Query: (%d, %d), Best_C: %f ---------------\\n' % (cnt, len(keys), ps, L, best_C))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # train model using all examples in training set and measure performance on test set\n",
    "    ssvm = SSVM(inference_train=inference_methods[method_ix], inference_pred=inference_methods[method_ix], \n",
    "                dat_obj=dat_obj, share_params=SSVM_SHARE_PARAMS, multi_label=SSVM_MULTI_LABEL, \n",
    "                C=best_C, poi_info=poi_info_i)#, debug=True)\n",
    "    if ssvm.train(sorted(trajid_set_i), n_jobs=N_JOBS) == True:\n",
    "        y_hat = ssvm.predict(ps, L)\n",
    "        print(cnt, y_hat)\n",
    "        if y_hat is not None:\n",
    "            recdict_ssvm[(ps, L)] = {'PRED': y_hat, 'W': ssvm.osssvm.w, 'C': ssvm.C}\n",
    "        \n",
    "    cnt += 1; #print_progress(cnt, len(keys)); sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F1_ssvm = []; pF1_ssvm = []; tau_ssvm = []\n",
    "for key in sorted(recdict_ssvm.keys()):\n",
    "    F1, pF1, tau = dat_obj.evaluate(key, recdict_ssvm[key]['PRED'])\n",
    "    F1_ssvm.append(F1); pF1_ssvm.append(pF1); tau_ssvm.append(tau)\n",
    "nF1 = np.sum([True if np.abs(x-1.0) < 1e-6 else False for x in F1_ssvm])\n",
    "npF1 = np.sum([True if np.abs(x-1.0) < 1e-6 else False for x in pF1_ssvm])\n",
    "print('SSVM: F1 (%.3f, %.3f), pairsF1 (%.3f, %.3f), Tau (%.3f, %.3f), perfectF1: %d/%d, perfectPairsF1: %d/%d' % \\\n",
    "      (np.mean(F1_ssvm), np.std(F1_ssvm)/np.sqrt(len(F1_ssvm)), \\\n",
    "       np.mean(pF1_ssvm), np.std(pF1_ssvm)/np.sqrt(len(pF1_ssvm)), \\\n",
    "       np.mean(tau_ssvm), np.std(tau_ssvm)/np.sqrt(len(tau_ssvm)), nF1, len(F1_ssvm), npF1, len(pF1_ssvm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fssvm = os.path.join(dat_obj.data_dir, 'ssvm-' + methods_suffix[method_ix] + '-' + dat_suffix[dat_ix] + '.pkl')\n",
    "pickle.dump(recdict_ssvm, open(fssvm, 'bw'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
