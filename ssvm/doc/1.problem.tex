\section{Problem formulation}
\label{sec:formulation}

The trajectory recommendation problem is: given a set of points-of-interest (POI) $\mathcal{P}$ and a trajectory query $\mathbf{x} = (s, K)$,
where $s \in \mathcal{P}$ is the desired start POI and $K > 1$ is the number of POIs in the desired trajectory (including the start location $s$).
We want to recommend a sequence of POIs $\mathbf{y}^*$ that maximises utility, i.e., for a suitable function $f(\cdot,\cdot)$,
\begin{equation*}
\mathbf{y}^* = \argmax_{\mathbf{y} \in \mathcal{Y}_\mathbf{x}}~f(\mathbf{x}, \mathbf{y}),
\end{equation*}
where $\mathcal{Y}_\mathbf{x}$ is the set of all possible trajectories with POIs in $\mathcal{P}$ and satisfying query $\mathbf{x}$.
$\mathbf{y} = (y_1 = s,~ y_2, \dots, y_K)$ is a trajectory with $K$ POIs, and $y_j \ne y_k$ if $j \ne k$ 
which is known as \emph{no duplicates constraint}.

Instead of the number of desired POIs, we can constrain the trajectory with a total time budget $T$.
In this case, the number of POIs $K$ can be treated as a \emph{hidden} variable, with additional constraint $\sum_{k=1}^K t_k \le T$ 
where $t_k$ is the time spent at POI $y_k$.



\subsection{A concrete example}
\label{sec:example}

Given a set of $10$ points-of-interest (POI) in Melbourne 
\begin{align*}
\mathcal{P} = \{ 
& \textit{\small Eureka Tower, Federation Square, Flinders Street Railway Station, Luna Park, Melbourne Aquarium, Melbourne Cricket Ground,} \\
& \textit{\small Melbourne Zoo, National Gallery of Victoria, Royal Exhibition Building, University of Melbourne} \}
\end{align*}
and a query $\mathbf{x} = \{\textit{\small University of Melbourne},~ 5\}$,
we would like to recommend a trajectory 
\begin{equation*}
\mathbf{y} = \{\textit{\small University of Melbourne},~ y_2, \dots, y_5\},~ y_k \in \mathcal{P},~ k=2,\dots,5.
\end{equation*}
by modelling trajectory data we have with POI and query related features as described in Section~\ref{sec:feature}.



\subsection{Related problems}
\label{sec:related}

This problem is related to automatic playlist generation, 
where we recommend a sequence of songs given a specified song (a.k.a. the seed) and the number of new songs.
Formally, given a library of songs and a query $\mathbf{x} = (s, K)$, where $s$ is the seed and $K$ is the number of songs in playlist,
we produce a list with $K$ songs (without duplication) by maximising the likelihood~\cite{chen2012playlist},
\begin{equation*}
%\max_{(y_1,\dots,y_K)} \prod_{k=2}^K \mathbb{P}(y_{k-1} \mid y_k),~ y_1 = s ~\text{and}~ y_j \ne y_k,~ j \ne k.
\mathbf{y}^* = \argmax_{\mathbf{y} \in \mathcal{P}_\mathbf{x}}~ \mathbb{P}(\mathbf{y} \mid \mathbf{x}),~ \mathbf{y} = (y_1=s,\dots,y_K) 
~\text{and}~ y_j \ne y_k ~\text{if}~ j \ne k.
\end{equation*}

Another similar problem is choosing a small set of photos from a large photo library and compiling them into a slideshow or movie.



\subsection{Evaluation metrics and loss functions}
\label{sec:evaluation}

To evaluate the performance of a certain recommendation algorithm,
we need to measure the similarity (or loss) given prediction $\hat{\mathbf{y}}$ and ground truth $\mathbf{y}$.
Metrics researchers have used include
\begin{itemize}
\item Hamming loss $\frac{1}{K} \sum_{j=1}^K \llb \hat{y}_j \neq y_j \rrb$, this checks if every position is the same.

\item F$_1$ score on points~\cite{ijcai15}, where we care about the set of correctly recommended POIs. 
      Let $\texttt{set}(\mathbf{y})$ denote the set of POIs in trajectory $\mathbf{y}$, F$_1$ score on points is defined as
\begin{equation*}
F_1 = \frac{2  P_{\textsc{point}}  R_{\textsc{point}}}{P_{\textsc{point}} + R_{\textsc{point}}} ~~\text{where}~
P_{\textsc{point}} = \frac{\mid \texttt{set}(\hat{\mathbf{y}}) \cap \texttt{set}(\mathbf{y}) \mid}{\mid \texttt{set}(\hat{\mathbf{y}}) \mid}~\text{and}~
R_{\textsc{point}} = \frac{\mid \texttt{set}(\hat{\mathbf{y}}) \cap \texttt{set}(\mathbf{y}) \mid}{\mid \texttt{set}(\mathbf{y}) \mid}.
\end{equation*}
If $\mid\!\! \hat{\mathbf{y}} \!\!\mid = \mid\!\! \mathbf{y} \!\!\mid$, this metric is just the unordered Hamming loss, 
i.e., Hamming loss between two binary indicator vectors of size $\mid\!\! \mathcal{P} \!\!\mid$.


\item F$_1$ score on pairs~\cite{cikm16paper}, where we care about the set of correctly predicted POI pairs,
\begin{equation*}
\text{pairs-F}_1 = \frac{2 P_{\textsc{pair}} R_{\textsc{pair}}}{P_{\textsc{pair}} + R_{\textsc{pair}}}~~\text{where}~
P_{\textsc{pair}} = \frac{N_c} {\mid \texttt{set}(\hat{\mathbf{y}}) \mid (\mid \texttt{set}(\hat{\mathbf{y}}) \mid - 1) / 2}~\text{and}~
R_{\textsc{pair}} = \frac{N_c} {\mid \texttt{set}(\mathbf{y}) \mid (\mid \texttt{set}(\mathbf{y}) \mid - 1) / 2},
\end{equation*}
and $N_c = \sum_{j=1}^{\mid \mathbf{y} \mid - 1} \sum_{k=j+1}^{\mid \mathbf{y} \mid} \llb y_j \prec_{\bar{\mathbf{y}}} y_k \rrb$,
here $y_j \prec_{\bar{\mathbf{y}}} y_k$ denotes that POI $y_j$ appears before POI $y_k$ in trajectory $\bar{\mathbf{y}}$.
We define pairs-F$_1 = 0$ when $N_c = 0$.

\end{itemize}

However, if we cast a trajectory $\mathbf{y} = (y_1,\dots,y_K)$ as a ranking of POIs in $\mathcal{P}$,
where $y_k$ has a rank $\mid\!\! \mathcal{P} \!\!\mid\! - k + 1$ and any other POI $p \notin \mathbf{y}$ has a rank $0$ ($0$ is an arbitrary choice).
We can make use of ranking evaluation metrics such as Kendall's $\tau$ or Spearman's $\rho$, by taking care of ties in ranks.

\eat{TODO: Write these down and contrast, esp. to pairs-F1}.



\subsection{Kendall's $\tau$}
\label{sec:kendalltau}

Given two ranks $X$ and $Y$, each with $n$ observations, we define
\begin{itemize}
\item Number of concordant pairs 
      \begin{equation*}
      %C = \sum_{i < j} \left( \mathbbm{1}(X_i < X_j) \cdot \mathbbm{1}(Y_i < Y_j) + \mathbbm{1}(X_i > X_j) \cdot \mathbbm{1}(Y_i > Y_j) \right),
      C = \frac{1}{2} \sum_{i,j} \left( \llb X_i < X_j \rrb \cdot \llb Y_i < Y_j \rrb + \llb X_i > X_j \rrb \cdot \llb Y_i > Y_j \rrb \right),
      \end{equation*}
      where $\llb \cdot \rrb$ is the indicator function and 
      $\sum_{i,j}$ means all ordered pairs $(i, j),~ i,j=1,\dots,n$ are counted twice.

\item Number of discordant pairs 
      \begin{equation*}
      D = \frac{1}{2} \sum_{i,j} \left( \llb X_i < X_j \rrb \cdot \llb Y_i > Y_j \rrb + \llb X_i > X_j \rrb \cdot \llb Y_i < Y_j \rrb \right).
      \end{equation*}

\item Number of ties in $X$
      \begin{equation*}
      T_X = \frac{1}{2} \sum_{i \ne j} \llb X_i = X_j \rrb = \sum_k \frac{t_k (t_k - 1)}{2},
      \end{equation*}
      where $t_k$ is the number of tied values in the $k$-th group of ties for $X$, for example, if
      $X = [12, 2, 1, 12, 2, 2, 1]$, there are $3$ groups of tied values, the first group is the two $12$'s, i.e., $t_1 = 2$;
      the second group is the three $2$'s, i.e., $t_2 = 3$; the third group is the two $1$'s, i.e., $t_3 = 2$. \\
      Similarly, the number of ties in $Y$ is 
      \begin{equation*}
      T_Y = \frac{1}{2} \sum_{i \ne j} \llb Y_i = Y_j \rrb = \sum_k \frac{u_k (u_k - 1)}{2},
      \end{equation*}
      where $u_k$ is the number of tied values in the $k$-th group of ties for $Y$.

\item Number of ties in both $X$ and $Y$
      \begin{equation*}
      T_{XY} = \frac{1}{2} \sum_{i \ne j} \llb X_i = X_j \rrb \cdot \llb Y_i = Y_j \rrb.
      \end{equation*}

\item Number of ties only in $X$
      \begin{equation*}
      T = \frac{1}{2} \sum_{i \ne j} \llb X_i = X_j \rrb \cdot \llb Y_i \ne Y_j \rrb,
      \end{equation*}
      and the number of ties only in $Y$
      \begin{equation*}
      U = \frac{1}{2} \sum_{i \ne j} \llb X_i \ne X_j \rrb \cdot \llb Y_i = Y_j \rrb.
      \end{equation*}
\end{itemize}

Kendall's $\tau$ (version $b$) is defined as~\cite{kendall1945,agresti2010analysis} (and implemented in SciPy~\cite{scipy})
\begin{equation*}
\tau_b = \frac{C - D}{\sqrt{[n(n-1)/2 - T_X] [n(n-1)/2 - T_Y]}} = \frac{C - D}{\sqrt{(C + D + T) (C + D + U)}},
\end{equation*}
where we use equalities 
\begin{align*}
\frac{n(n-1)}{2} &= C + D + T_X + T_Y - T_{XY} \\
T &= T_X - T_{XY} \\
U &= T_Y - T_{XY}
\end{align*}



\subsection{Compare Kendall's $\tau$ with F$_1$ score on points and pairs}
\label{sec:metriccomparison}

Given a prediction $\hat{\mathbf{y}} = (\hat{y}_1, \hat{y}_2, \dots, \hat{y}_K)$ and ground truth $\mathbf{y} = (y_1, y_2, \dots, y_K)$,
for a specific ordering of POIs $(p_1, p_2, \dots, p_{\mid\mathcal{P}\mid})$,
we produce two ranks according to $\mathbf{y}$ and $\hat{\mathbf{y}}$,
\begin{align*}
r_{\mathbf{y}}^i       &= \sum_{j=1}^K (\mid\!\! \mathcal{P} \!\!\mid - j + 1) \cdot \llb p_i = y_j \rrb,~
i = 1, \dots, \mid\!\! \mathcal{P} \!\!\mid \\
r_{\hat{\mathbf{y}}}^i &= \sum_{j=1}^K (\mid\!\! \mathcal{P} \!\!\mid - j + 1) \cdot \llb p_i = \hat{y}_j \rrb,~ 
i = 1, \dots, \mid\!\! \mathcal{P} \!\!\mid
\end{align*}
where POIs not in $\mathbf{y}$ will have a rank of $0$ in $r_{\mathbf{y}}$ and similarly in $r_{\hat{\mathbf{y}}}$.
Then we have
\begin{align*}
C &= \frac{1}{2} \sum_{i,j} \left(\llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb +
     \llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \right), \\
D &= \frac{1}{2} \sum_{i,j} \left(\llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb +
     \llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \right), \\
T_{\mathbf{y}}       &= \frac{1}{2} \sum_{i \ne j} \llb r_{\mathbf{y}}^i = r_{\mathbf{y}}^j \rrb, \\
T_{\hat{\mathbf{y}}} &= \frac{1}{2} \sum_{i \ne j} \llb r_{\hat{\mathbf{y}}}^i = r_{\hat{\mathbf{y}}}^j \rrb, \\
T_{\mathbf{y},\hat{\mathbf{y}}} &= \frac{1}{2} \sum_{i \ne j} \llb r_{\hat{\mathbf{y}}}^i = r_{\hat{\mathbf{y}}}^j \rrb \cdot
                                   \llb r_{\mathbf{y}}^i = r_{\mathbf{y}}^j \rrb, \\
T &= T_{\mathbf{y}} - T_{\mathbf{y},\hat{\mathbf{y}}},~ U = T_{\hat{\mathbf{y}}} - T_{\mathbf{y},\hat{\mathbf{y}}}.
\end{align*}
\noindent
Kendall's $\tau$
\begin{equation*}
\tau_b = \frac{C - D}{\sqrt{(C + D + T) (C + D + U)}},
\end{equation*}
F$_1$ score on points 
\begin{equation*}
F_1 = \frac{1}{K} \sum_i \llb r_{\mathbf{y}}^i > 0 \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i > 0 \rrb,
\end{equation*}
and F$_1$ score on pairs
\begin{equation*}
\text{pairs-F}_1 = \frac{\frac{1}{2} \sum_{i,j} 
                   \llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^i > 0 \rrb \cdot
                   \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i > 0 \rrb +
                   \frac{1}{2} \sum_{i,j} 
                   \llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^j > 0 \rrb \cdot
                   \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^j > 0 \rrb}{K(K-1)/2}.
\end{equation*}

We can rewrite the number of concordant pairs as
\begin{align*}
C =& \frac{1}{2} \sum_{i,j} \left(\llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb +
     \llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \right), \\
  =& \sum_{i < j} \llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot 
     \left( \llb r_{\mathbf{y}}^i > 0 \rrb + \llb r_{\mathbf{y}}^i = 0 \rrb \right) \cdot 
     \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \cdot
     \left( \llb r_{\hat{\mathbf{y}}}^i > 0 \rrb + \llb r_{\hat{\mathbf{y}}}^i = 0 \rrb \right) + \\
   & \sum_{i < j} \llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot 
     \left( \llb r_{\mathbf{y}}^j > 0 \rrb + \llb r_{\mathbf{y}}^j = 0 \rrb \right) \cdot
     \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \cdot
     \left( \llb r_{\hat{\mathbf{y}}}^j > 0 \rrb + \llb r_{\hat{\mathbf{y}}}^j = 0 \rrb \right) \\
  =& \sum_{i < j} \left( \uwave{\llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^i > 0 \rrb} +
            \llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^i = 0 \rrb \right) \cdot 
     \left( \uwave{\llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i > 0 \rrb} + 
            \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i = 0 \rrb \right) + \\
   & \sum_{i < j} \left( \uwave{\llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^j > 0 \rrb} + 
            \llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^j = 0 \rrb \right) \cdot
     \left( \uwave{\llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^j > 0 \rrb} + 
            \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^j = 0 \rrb \right) \\
  =& \sum_{i < j} \uwave{\llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^i > 0 \rrb \cdot
                         \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i > 0 \rrb} +
     \sum_{i < j} \uwave{\llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^j > 0 \rrb \cdot
                         \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^j > 0 \rrb} + \\
   & \sum_{i < j} \left( \uwave{\llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^i > 0 \rrb} \cdot
                         \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i = 0 \rrb + 
                         \llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^i = 0 \rrb \cdot 
                         \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \right) + \\ 
   & \sum_{i < j} \left( \uwave{\llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^j > 0 \rrb} \cdot
                         \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^j = 0 \rrb +
                         \llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^j = 0 \rrb \cdot
                         \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \right) \\
  =& ~\text{pairs-F}_1 \cdot \frac{K(K-1)}{2}~ + \\
   & \sum_{i < j} \left( \uwave{\llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^i > 0 \rrb} \cdot
                         \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^i = 0 \rrb + 
                         \llb r_{\mathbf{y}}^i < r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^i = 0 \rrb \cdot 
                         \llb r_{\hat{\mathbf{y}}}^i < r_{\hat{\mathbf{y}}}^j \rrb \right) + \\ 
   & \sum_{i < j} \left( \uwave{\llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^j > 0 \rrb} \cdot
                         \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \cdot \llb r_{\hat{\mathbf{y}}}^j = 0 \rrb +
                         \llb r_{\mathbf{y}}^i > r_{\mathbf{y}}^j \rrb \cdot \llb r_{\mathbf{y}}^j = 0 \rrb \cdot
                         \llb r_{\hat{\mathbf{y}}}^i > r_{\hat{\mathbf{y}}}^j \rrb \right).
\end{align*}
